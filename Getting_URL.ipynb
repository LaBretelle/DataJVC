{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 918/918 [23:44<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "    \n",
    "a = 0\n",
    "with open('list_url.csv', mode='w') as datacsv:\n",
    "    datacsv = csv.writer(datacsv, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in tqdm(range(1,919)):\n",
    "        url = \"https://www.jeuxvideo.com/tests/?p={}\".format(i)\n",
    "        r = urlopen(url).read()\n",
    "        soup= BeautifulSoup(r)\n",
    "        for href in soup.findAll('a', href=True) :\n",
    "            if \"/test/\" in href['href']:\n",
    "                a += 1\n",
    "                line = \"https://jeuxvideo.com\" + href['href']\n",
    "                datacsv.writerow([line])\n",
    "            elif \"/articles/\" in href['href']:\n",
    "                a += 1\n",
    "                line = \"https://jeuxvideo.com\" + href['href']\n",
    "                datacsv.writerow([line])\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18348it [5:28:09,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import re\n",
    "\n",
    "\n",
    "with open('list_url.csv', mode='r') as list_url:\n",
    "    csv_reader = csv.reader(list_url, delimiter=',')\n",
    "    with open('datajvctest.csv', mode='w') as datacsv:\n",
    "        datacsv = csv.writer(datacsv, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        datacsv.writerow([\"titre\", \"console\", \"note_testeur\", \"nom_testeur\", \"statut_testeur\", \"year\", \"date_test\", \"note_lecteur\", \"nombre_testeur\", \"url\"])\n",
    "        for row in tqdm(csv_reader):\n",
    "            url = row[0]\n",
    "            r = urlopen(url).read()\n",
    "            soup= BeautifulSoup(r)\n",
    "            #I take the title in the meta:title tags\n",
    "            titre_meta = soup.find('title').text\n",
    "            titre_extended = titre_meta.replace(\"Test de \", \"\")\n",
    "            titre = re.search(r\".* :|.* sur|.* par\", titre_extended).group(0)\n",
    "            titre = titre.replace(\" :\", \"\")\n",
    "            titre = titre.replace(\" sur\",\"\")\n",
    "            titre = titre.replace(\" par\",\"\")\n",
    "            # I take all informations in tester div\n",
    "            div_note_testeur = soup.find('div', {\"class\":\"bloc-avis-testeur\"})\n",
    "            note_testeur = div_note_testeur.find('strong').text\n",
    "            nom_testeur = div_note_testeur.find('nowiki').text\n",
    "            try :\n",
    "                statut_testeur = div_note_testeur.find('div', {\"class\":\"statut\"}).text\n",
    "            except :\n",
    "                statut_testeur = \"\"\n",
    "            date_test = div_note_testeur.find('div', {\"class\":\"date\"}).text\n",
    "            year = re.search(r\" \\d{4} \", date_test).group(0)\n",
    "            year = year.replace(\" \", \"\")\n",
    "            # I take all informations in readers div\n",
    "            div_note_lecteur = soup.find('div', {\"class\":\"bloc-avis-lecteur\"})\n",
    "            try :\n",
    "                note_lecteur = div_note_lecteur.find('strong').text\n",
    "            except : #sometimes, no one gave a note\n",
    "                note_lecteur = \"\"\n",
    "            nombre_testeur = div_note_lecteur.find('div', {\"class\":\"auteur\"}).text\n",
    "            try :\n",
    "                nombre_testeur = re.search(r\"([0-9]+)\", nombre_testeur).group(0)\n",
    "            except :\n",
    "                nombre_testeur = \"\"\n",
    "            try :\n",
    "                console = re.search(r\"sur.*par\", titre_extended).group(0)\n",
    "                console = console.replace(\"sur \", \"\")\n",
    "                console = console.replace(\" par\", \"\")\n",
    "            except :\n",
    "                console = \"\"\n",
    "            datacsv.writerow([titre, console, note_testeur, nom_testeur, statut_testeur, year, date_test, note_lecteur, nombre_testeur, url])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
